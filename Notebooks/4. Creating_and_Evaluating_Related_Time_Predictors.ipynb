{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Creating and Evaluating Predictors - Related Time Series\n",
    "\n",
    "This notebook will build off of all the earlier work and requires that at least the importing of target time series and related time series data be complete. If you have not performed those steps yet, go back, do so, then continue.\n",
    "\n",
    "At this point, you now have a target-time-series dataset and a related-time-series dataset loaded into a singular Dataset Group, this is what is required to leverage the models that support related data in Amazon Forecast. If your data supports item-level metadata, it could be added to the dataset group as well and would benefit only DeepAR+. \n",
    "\n",
    "To continue the work, start with the imports, determine your region, establish your API connections, and load all previously stored values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region)\n",
    "forecast = session.client(service_name='forecast')\n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training Predictors\n",
    " \n",
    "Given that our data is hourly and we want to generate a forecast on the hour, Forecast limits us to a horizon of 500 of whatever the slice is. This means we will be able to predict about 20 days into the future.\n",
    "\n",
    "The cells below will define a few variables to be used with all of our models. Then there will be an API call to create each `Predictor` where they are based on Prophet and DeepAR+ respectfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastHorizon = 480\n",
    "NumberOfBacktestWindows = 4\n",
    "BackTestWindowOffset = 480\n",
    "ForecastFrequency = \"H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_algorithmArn = 'arn:aws:forecast:::algorithm/Prophet'\n",
    "deepAR_Plus_algorithmArn = 'arn:aws:forecast:::algorithm/Deep_AR_Plus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet Specifics\n",
    "# Note the REL to indicate related time series data\n",
    "prophet_predictorName = project+'_proph_rel'\n",
    "print(prophet_predictorName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Prophet:\n",
    "prophet_create_predictor_response=forecast.create_predictor(\n",
    "    PredictorName=prophet_predictorName, \n",
    "    AlgorithmArn=prophet_algorithmArn,\n",
    "    ForecastHorizon=forecastHorizon,\n",
    "    PerformAutoML= False,\n",
    "    PerformHPO=False,\n",
    "    EvaluationParameters={\n",
    "        \"NumberOfBacktestWindows\": NumberOfBacktestWindows, \n",
    "        \"BackTestWindowOffset\": BackTestWindowOffset\n",
    "    }, \n",
    "    InputDataConfig={\n",
    "        \"DatasetGroupArn\": datasetGroupArn, \n",
    "        \"SupplementaryFeatures\": [ \n",
    "                     { \n",
    "                        \"Name\": \"holiday\",\n",
    "                        \"Value\": \"US\"\n",
    "                     }\n",
    "                  ]\n",
    "        },\n",
    "    FeaturizationConfig={\n",
    "        \"ForecastFrequency\": ForecastFrequency, \n",
    "        \"Featurizations\": [\n",
    "                        {\n",
    "                            \"AttributeName\": \"target_value\", \n",
    "                            \"FeaturizationPipeline\": [\n",
    "                              {\n",
    "                                  \"FeaturizationMethodName\": \"filling\", \n",
    "                                  \"FeaturizationMethodParameters\": \n",
    "                                  {\n",
    "                                      \"frontfill\": \"none\", \n",
    "                                      \"middlefill\": \"zero\", \n",
    "                                      \"backfill\": \"zero\"\n",
    "                                  }\n",
    "                              }\n",
    "                            ]\n",
    "                          }\n",
    "                        ]\n",
    "    }\n",
    " )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepAR+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR+ Specifics\n",
    "deeparp_predictorName= project+'_deep_rel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DeepAR+:\n",
    "deeparp_create_predictor_response=forecast.create_predictor(\n",
    "    PredictorName=deeparp_predictorName, \n",
    "    AlgorithmArn=deepAR_Plus_algorithmArn,\n",
    "    ForecastHorizon=forecastHorizon,\n",
    "    PerformAutoML= False,\n",
    "    PerformHPO=False,\n",
    "    EvaluationParameters= {\n",
    "        \"NumberOfBacktestWindows\": NumberOfBacktestWindows, \n",
    "        \"BackTestWindowOffset\": BackTestWindowOffset\n",
    "    }, \n",
    "    InputDataConfig={\n",
    "        \"DatasetGroupArn\": datasetGroupArn, \n",
    "        \"SupplementaryFeatures\": [ \n",
    "                     { \n",
    "                        \"Name\": \"holiday\",\n",
    "                        \"Value\": \"US\"\n",
    "                     }\n",
    "                  ]\n",
    "    },\n",
    "    FeaturizationConfig={\n",
    "        \"ForecastFrequency\": ForecastFrequency, \n",
    "        \"Featurizations\": [\n",
    "            {\n",
    "                \"AttributeName\": \"target_value\", \n",
    "                \"FeaturizationPipeline\": [\n",
    "                    {\n",
    "                        \"FeaturizationMethodName\": \"filling\", \n",
    "                        \"FeaturizationMethodParameters\": \n",
    "                                {\n",
    "                                    \"frontfill\": \"none\", \n",
    "                                     \"middlefill\": \"zero\", \n",
    "                                     \"backfill\": \"zero\"\n",
    "                                }\n",
    "                              }\n",
    "                            ]\n",
    "                          }\n",
    "                        ]\n",
    "    }\n",
    " )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the training status in the Forecast [console](https://console.aws.amazon.com/forecast/home?region=us-east-1#landing).\n",
    "\n",
    "Also, you can run the following cell, cause it includes the await condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the Predictors\n",
    "\n",
    "Once each of the Predictors is in an `Active` state, you can get metrics about it to better understand its accuracy and behavior. These are computed based on the hold out periods we defined when building the Predictor. The metrics are meant to guide our decisions when we use a particular Predictor to generate a forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet\n",
    "\n",
    "Here we are going to look to see the metrics from this Predictor like the earlier sessions, we will now add the related data metrics to the table from the previous notebook as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Await till training completion\n",
    "while True:\n",
    "    modelTrainStatus = forecast.describe_predictor(\n",
    "        PredictorArn=prophet_create_predictor_response[\"PredictorArn\"]\n",
    "    )['Status']\n",
    "    print(modelTrainStatus)\n",
    "    if modelTrainStatus != 'ACTIVE' and modelTrainStatus != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Prophet Metrics\n",
    "prophet_with_related_data_arn = prophet_create_predictor_response['PredictorArn']\n",
    "prophet_with_related_data_metrics = forecast.get_accuracy_metrics(PredictorArn=prophet_with_related_data_arn)\n",
    "\n",
    "prophet_with_related_data_summary_metrics = prophet_with_related_data_metrics[\"PredictorEvaluationResults\"][0][\"TestWindows\"][0]\n",
    "\n",
    "\n",
    "prophet_display_data = {\n",
    "    \"RMSE\": [\n",
    "        prophet_summary_metrics[\"Metrics\"][\"RMSE\"],\n",
    "        prophet_with_related_data_summary_metrics[\"Metrics\"][\"RMSE\"]\n",
    "    ],\n",
    "    \"10%\" : [\n",
    "        prophet_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"],\n",
    "        prophet_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"]\n",
    "    ],\n",
    "    \"50%\" : [\n",
    "        prophet_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][1][\"LossValue\"],\n",
    "        prophet_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][1][\"LossValue\"]\n",
    "    ],\n",
    "    \"90%\" : [\n",
    "        prophet_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][0][\"LossValue\"],\n",
    "        prophet_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][0][\"LossValue\"]\n",
    "    ]\n",
    "}\n",
    "prophet_display_data_frame = pd.DataFrame(prophet_display_data, [\"Prophet\", \"Prophet+Related Data\"])\n",
    "\n",
    "display(prophet_display_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison with previous results, we haven't got a significant increase in the accuracy. In some cases it even could be a step back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepAR+\n",
    "\n",
    "Same as Prophet, now you should look at the metrics from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Await till training completion\n",
    "while True:\n",
    "    modelTrainStatus = forecast.describe_predictor(\n",
    "        PredictorArn=deeparp_create_predictor_response[\"PredictorArn\"]\n",
    "    )['Status']\n",
    "    print(modelTrainStatus)\n",
    "    if modelTrainStatus != 'ACTIVE' and modelTrainStatus != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# DeepAR+ Metrics\n",
    "deeparp_with_related_data_arn = deeparp_create_predictor_response['PredictorArn']\n",
    "deeparp_with_related_data_metrics = forecast.get_accuracy_metrics(PredictorArn=deeparp_with_related_data_arn)\n",
    "\n",
    "deeparp_with_related_data_summary_metrics = deeparp_with_related_data_metrics[\"PredictorEvaluationResults\"][0][\"TestWindows\"][0]\n",
    "\n",
    "deeparp_display_data = {\n",
    "    \"RMSE\": [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"RMSE\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"RMSE\"]\n",
    "    ],\n",
    "    \"10%\" : [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"]\n",
    "    ],\n",
    "    \"50%\" : [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][1][\"LossValue\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][1][\"LossValue\"]\n",
    "    ],\n",
    "    \"90%\" : [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][0][\"LossValue\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][0][\"LossValue\"]\n",
    "    ]\n",
    "}\n",
    "deeparp_display_data_frame = pd.DataFrame(deeparp_display_data, [\"DeepAR+\", \"DeepAR+ + Related Data\"])\n",
    "\n",
    "display(deeparp_display_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the resultant metrics, the DeepAR+ with related data shows the best results for 10% and 50% quantiles.\n",
    "\n",
    "Additional work would need to be kicked off from here to determine the specific impact of these figures and how they compare to the existing Forecasting approaches performed by your customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Example\n",
    "\n",
    "Not sure which algorithm does fit best for your data? Allow the forecast to evaluate which one does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML Specifics\n",
    "automl_predictorName= project+'_automl_test'\n",
    "\n",
    "# Build AutoML:\n",
    "automl_create_predictor_response=forecast.create_predictor(\n",
    "    PredictorName=automl_predictorName, \n",
    "    ForecastHorizon=forecastHorizon,\n",
    "    PerformAutoML= True,\n",
    "    PerformHPO=False,\n",
    "    EvaluationParameters= {\n",
    "        \"NumberOfBacktestWindows\": NumberOfBacktestWindows, \n",
    "        \"BackTestWindowOffset\": BackTestWindowOffset\n",
    "    }, \n",
    "    InputDataConfig={\n",
    "        \"DatasetGroupArn\": datasetGroupArn, \n",
    "        \"SupplementaryFeatures\": [ \n",
    "                     { \n",
    "                        \"Name\": \"holiday\",\n",
    "                        \"Value\": \"US\"\n",
    "                     }\n",
    "                  ]\n",
    "    },\n",
    "    FeaturizationConfig={\n",
    "        \"ForecastFrequency\": ForecastFrequency, \n",
    "        \"Featurizations\": [\n",
    "            {\n",
    "                \"AttributeName\": \"target_value\", \n",
    "                \"FeaturizationPipeline\": [\n",
    "                    {\n",
    "                        \"FeaturizationMethodName\": \"filling\", \n",
    "                        \"FeaturizationMethodParameters\": \n",
    "                                {\n",
    "                                    \"frontfill\": \"none\", \n",
    "                                     \"middlefill\": \"zero\", \n",
    "                                     \"backfill\": \"zero\"\n",
    "                                }\n",
    "                              }\n",
    "                            ]\n",
    "                          }\n",
    "                        ]\n",
    "    }\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Await till training completion\n",
    "while True:\n",
    "    modelTrainStatus = forecast.describe_predictor(\n",
    "        PredictorArn=automl_create_predictor_response[\"PredictorArn\"]\n",
    "    )['Status']\n",
    "    print(modelTrainStatus)\n",
    "    if modelTrainStatus != 'ACTIVE' and modelTrainStatus != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML\n",
    "automl_arn = automl_create_predictor_response['PredictorArn']\n",
    "automl_metrics = forecast.get_accuracy_metrics(PredictorArn=deeparp_arn)\n",
    "\n",
    "automl_summary_metrics = automl_metrics[\"PredictorEvaluationResults\"][0][\"TestWindows\"][0]\n",
    "\n",
    "automl_display_data = {\n",
    "    \"RMSE\": [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"RMSE\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"RMSE\"],\n",
    "        automl_summary_metrics[\"Metrics\"][\"RMSE\"]\n",
    "    ],\n",
    "    \"10%\" : [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"],\n",
    "        automl_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"]\n",
    "    ],\n",
    "    \"50%\" : [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][1][\"LossValue\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][1][\"LossValue\"],\n",
    "        automl_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"]\n",
    "    ],\n",
    "    \"90%\" : [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][0][\"LossValue\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][0][\"LossValue\"],\n",
    "        automl_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"]\n",
    "    ]\n",
    "}\n",
    "automl_display_data_frame = pd.DataFrame(automl_display_data, [\"DeepAR+\", \"DeepAR+ + Related Data\", \"AutoML\"])\n",
    "\n",
    "display(automl_display_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR+ HPO Auto-Tuning\n",
    "\n",
    "Depending on the hyperparameters model can produce different metrics. Manual tuning of such parameters is routine labor, so for the DeepAR+ Forecast provides an ability to automatically test different hyperparameters and choose the best one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR+ Specifics\n",
    "deeparp_hpo_predictorName= project+'_deep_hpo'\n",
    "\n",
    "# Build DeepAR+:\n",
    "deeparp_hpo_create_predictor_response=forecast.create_predictor(\n",
    "    PredictorName=deeparp_hpo_predictorName, \n",
    "    AlgorithmArn=deepAR_Plus_algorithmArn,\n",
    "    ForecastHorizon=forecastHorizon,\n",
    "    PerformAutoML= False,\n",
    "    PerformHPO=True,\n",
    "    EvaluationParameters= {\n",
    "        \"NumberOfBacktestWindows\": NumberOfBacktestWindows, \n",
    "        \"BackTestWindowOffset\": BackTestWindowOffset\n",
    "    }, \n",
    "    InputDataConfig={\n",
    "        \"DatasetGroupArn\": datasetGroupArn, \n",
    "        \"SupplementaryFeatures\": [ \n",
    "                     { \n",
    "                        \"Name\": \"holiday\",\n",
    "                        \"Value\": \"US\"\n",
    "                     }\n",
    "                  ]\n",
    "    },\n",
    "    FeaturizationConfig={\n",
    "        \"ForecastFrequency\": ForecastFrequency, \n",
    "        \"Featurizations\": [\n",
    "            {\n",
    "                \"AttributeName\": \"target_value\", \n",
    "                \"FeaturizationPipeline\": [\n",
    "                    {\n",
    "                        \"FeaturizationMethodName\": \"filling\", \n",
    "                        \"FeaturizationMethodParameters\": \n",
    "                                {\n",
    "                                    \"frontfill\": \"none\", \n",
    "                                     \"middlefill\": \"zero\", \n",
    "                                     \"backfill\": \"zero\"\n",
    "                                }\n",
    "                              }\n",
    "                            ]\n",
    "                          }\n",
    "                        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Await\n",
    "while True:\n",
    "    modelTrainStatus = forecast.describe_predictor(\n",
    "        PredictorArn=deeparp_hpo_create_predictor_response[\"PredictorArn\"]\n",
    "    )['Status']\n",
    "    print(modelTrainStatus)\n",
    "    if modelTrainStatus != 'ACTIVE' and modelTrainStatus != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "# Metrics        \n",
    "        \n",
    "deeparp_hpo_arn = deeparp_hpo_create_predictor_response['PredictorArn']\n",
    "deeparp_hpo_metrics = forecast.get_accuracy_metrics(PredictorArn=deeparp_hpo_arn)\n",
    "\n",
    "deeparp_hpo_summary_metrics = deeparp_hpo_metrics[\"PredictorEvaluationResults\"][0][\"TestWindows\"][0]\n",
    "\n",
    "deeparp_hpo_display_data = {\n",
    "    \"RMSE\": [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"RMSE\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"RMSE\"],\n",
    "        deeparp_hpo_summary_metrics[\"Metrics\"][\"RMSE\"]\n",
    "    ],\n",
    "    \"10%\" : [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"],\n",
    "        deeparp_hpo_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"]\n",
    "    ],\n",
    "    \"50%\" : [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][1][\"LossValue\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][1][\"LossValue\"],\n",
    "        deeparp_hpo_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"]\n",
    "    ],\n",
    "    \"90%\" : [\n",
    "        deepar_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][0][\"LossValue\"],\n",
    "        deeparp_with_related_data_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][0][\"LossValue\"],\n",
    "        deeparp_hpo_summary_metrics[\"Metrics\"][\"WeightedQuantileLosses\"][2][\"LossValue\"]\n",
    "    ]\n",
    "}\n",
    "deeparp_hpo_display_data_frame = pd.DataFrame(deeparp_hpo_display_data, [\"DeepAR+\", \"DeepAR+ + Related Data\", \"DeepAR+ +Related Data +HPO\"])\n",
    "\n",
    "display(deeparp_hpo_display_data_frame)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we got even better results for the DeepAR+ HPO job. The drawbacks:\n",
    "- More time to train the model\n",
    "- HPO could produce a more efficient result than the no-using HPO, but it may not provide the best possible outcome. Choosing subsets of the hyperparameters is a non-trivial task, at least because there is an infinite number of them.\n",
    "\n",
    "\n",
    "> As a general best practice, you have to provide the `HPOConfig` parameter to the HPO Auto-Tuning predictor to narrow down the optimization field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
